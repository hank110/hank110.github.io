<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>Hank's Notes</title>
    <link href="../static/css/bootstrap.min.css" rel="stylesheet">
    <link href="../static/css/custom.css" rel="stylesheet">
    <script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="./static/js/jquery.min.js") }}">\x3C/script>')</script>
    <script type="text/javascript" src="../static/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../static/js/d3.v3.min.js"></script>
    <link href='http://fonts.googleapis.com/css?family=Play' rel='stylesheet' type='text/css'>
  </head>
  <body>
    <header>
    

<nav class="navbar" role="navigation">
  <div class="container container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand"><span id="logo"></span><span id="title">Hank's Notes</span></a>
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav" style = "padding-left:30px;">
        
            
            <li><a href="./index.html">Home</a></li>
            
        
            
            <li><a href="./blogs.html">Blogs</a></li>
            
        
      </ul>
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>
    </header>

    <div class="container">
    

<body>
	<h3><strong>Character-Aware Neural Language Models (Kim et al, 2016)</strong></h3>
<h4><strong>Overview:</strong></h4>
<ul>
<li>
<p>Language model = finding a probability distribution over a sequence of words (traditionally estimated n-gram probabilities)</p>
</li>
<li>
<p>This model trains CNN + RNN to create language model based on <strong>character level embedding</strong></p>
</li>
<li>
<p>Advantages of character level embedding:</p>
<ul>
<li>
<p>No need for morphological tagging</p>
</li>
<li>
<p>Can embed morphological properties of an input language</p>
</li>
<li>
<p>Free from out-of-vocabulary issues</p>
</li>
</ul>
</li>
</ul>
<h4><strong>Key Results:</strong></h4>
<p><img alt="E" src="./static/img/0_character_level_cnn.png" /></p>
<ul>
<li>
<p>Architecture:</p>
<ol>
<li>
<p>Embedding vector of each character is concatenated to form matrix representation of each word</p>
</li>
<li>
<p>Convolution with multiple filters, which essentially picking out n-grams of characters</p>
</li>
<li>
<p>Max-pooling to create a fixed dimensional word vector</p>
</li>
<li>
<p>Apply Highway Network to the word vector</p>
<ul>
<li>
<p><img alt="E" src="./static/img/0_highway_network.png" /></p>
</li>
<li>
<p>Instead of complete non-linear transformation, it is a weighted non-linear transformation</p>
</li>
<li>
<p>Using additional affine transformation + non-linearity as "carry gate", this network adaptively carries some meaningful information of the input vector directy to the output vector.</p>
</li>
</ul>
</li>
<li>
<p>LSTM to predict the subsequent word for the given input word (trained on cross entropy loss) </p>
</li>
</ol>
</li>
</ul>
<h4><strong>Comments:</strong></h4>
<ul>
<li>
<p>While word embedding vectors focus on the contextual information of the input's surrounding words, this model relies on the context of each character within the word to generate word vectors.</p>
</li>
<li>
<p>In a way, it can create more isolated/localized embedding of a word that captures the internal structure or the morphological properties of a word (Representing words in different dimensional space)</p>
</li>
<li>
<p>No wonder combination of this localized embedding method with traditional word2vec like word embedding method shows improved performance in various NLP tasks</p>
</li>
</ul>
</body>


    </div>
 </body>
</html>